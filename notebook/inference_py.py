# -*- coding: utf-8 -*-
"""Inference.pynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ja384ARu0L642B0suEAP4IYNsMRaPyrQ
"""

pip install gradio

pip install transformers

from transformers import AutoModelForSequenceClassification
from transformers import TFAutoModelForSequenceClassification
from transformers import AutoTokenizer, AutoConfig
import numpy as np
from scipy.special import softmax

from transformers import AutoConfig
id2label = {
  "0": "Negative",
  "1": "Neutral",
  "2": "Positive"
}

from transformers import AutoModel, AutoTokenizer

model_path = "Henok21/test_trainer"

config = AutoConfig.from_pretrained(model_path , id2label=id2label)
model = AutoModelForSequenceClassification.from_pretrained(model_path , config  = config)

# Preprocess text (username and link placeholders)
def preprocess(text):
    new_text = []
    for t in text.split(" "):
        t = '@user' if t.startswith('@') and len(t) > 1 else t
        t = 'http' if t.startswith('http') else t
        new_text.append(t)
    return " ".join(new_text)

text = "medicen is best!"
text = preprocess(text)
text

# PyTorch-based models

tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')

encoded_input = tokenizer(text, return_tensors='pt')
output = model(**encoded_input)
scores = output[0][0].detach().numpy()
scores = softmax(scores)
scores

config.id2label = {0: 'NEGATIVE', 1: 'NEUTRAL', 2: 'POSITIVE'}

# Print labels and scores
ranking = np.argsort(scores)
ranking = ranking[::-1]
for i in range(scores.shape[0]):
    l = config.id2label[ranking[i]]
    s = scores[ranking[i]]
    print(f"{i+1}) {l} {np.round(float(s), 4)}")

model_path = "Henok21/test_trainer"

"""# Gradio App"""



import gradio as gr

def sentiment_analysis(text):
  text = preprocess(text)

  # PyTorch-based models
  encoded_input = tokenizer(text, return_tensors='pt')
  output = model(**encoded_input)
  scores_ = output[0][0].detach().numpy()
  scores_ = softmax(scores_)

  labels = ["Negative" , "Neutral" , "Positive"]
  scores = {l : float(s) for (l , s) in zip(labels , scores_)}

  return scores

# Import the pipeline class
from transformers import pipeline

# Create a model
model = model

# Create a tokenizer
tokenizer = tokenizer

# Create a pipeline object for sentiment analysis using your model and tokenizer
nlp = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer,  config = config)

# Use the pipeline object on some input text
result = nlp("I love this movie!")

# Print the result
print(result)

config.label2id = {
    "Negative" : 0 ,
    "Neutral" : 1 ,
    "Positive" : 2
}

sentiment_analysis("covid is good")

demo = gr.Interface(
    fn = sentiment_analysis,
    inputs = gr.Textbox(placeholder = "write down"),
    outputs = "text",
    interpretation = "default",
    examples = [
        ["whats up with the vaccine"],
        ["i don't like it"]
    ]
)

demo.launch()

